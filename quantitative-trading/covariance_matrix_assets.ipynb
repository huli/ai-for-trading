{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variance of one stock\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SQLAlchemy==1.3.22 (from -r requirements.txt (line 1))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/6d/d9b346436a2eca643d836989941077818134fa3d830064bbfff1983ec09c/SQLAlchemy-1.3.22-cp36-cp36m-manylinux1_x86_64.whl (1.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.3MB 6.3MB/s eta 0:00:01    86% |███████████████████████████▋    | 1.1MB 12.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy==1.14.5 (from -r requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/1e/116ad560de97694e2d0c1843a7a0075cc9f49e922454d32f49a80eb6f1f2/numpy-1.14.5-cp36-cp36m-manylinux1_x86_64.whl (12.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 12.2MB 1.0MB/s eta 0:00:01  2% |▊                               | 266kB 12.7MB/s eta 0:00:01    17% |█████▌                          | 2.1MB 21.2MB/s eta 0:00:01    22% |███████▏                        | 2.7MB 25.2MB/s eta 0:00:01    31% |██████████                      | 3.8MB 12.6MB/s eta 0:00:01    36% |███████████▊                    | 4.5MB 12.7MB/s eta 0:00:01    41% |█████████████▏                  | 5.0MB 12.6MB/s eta 0:00:01    46% |██████████████▉                 | 5.6MB 15.5MB/s eta 0:00:01    56% |██████████████████              | 6.9MB 12.9MB/s eta 0:00:01    61% |███████████████████▊            | 7.5MB 11.3MB/s eta 0:00:01    71% |██████████████████████▊         | 8.6MB 12.4MB/s eta 0:00:01    92% |█████████████████████████████▋  | 11.2MB 12.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandas==0.18.1 (from -r requirements.txt (line 3))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/09/e66eb844daba8680ddff26335d5b4fead77f60f957678243549a8dd4830d/pandas-0.18.1.tar.gz (7.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 7.3MB 2.3MB/s eta 0:00:01   2% |▉                               | 194kB 14.0MB/s eta 0:00:01    12% |████                            | 901kB 7.1MB/s eta 0:00:01    26% |████████▋                       | 2.0MB 12.8MB/s eta 0:00:01    35% |███████████▍                    | 2.6MB 27.6MB/s eta 0:00:01    44% |██████████████▏                 | 3.2MB 13.0MB/s eta 0:00:01    52% |█████████████████               | 3.9MB 12.9MB/s eta 0:00:01    69% |██████████████████████▏         | 5.0MB 13.5MB/s eta 0:00:01    85% |███████████████████████████▍    | 6.2MB 12.6MB/s eta 0:00:01    93% |██████████████████████████████  | 6.8MB 11.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting plotly==2.2.3 (from -r requirements.txt (line 4))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/a6/8214b6564bf4ace9bec8a26e7f89832792be582c042c47c912d3201328a0/plotly-2.2.3.tar.gz (1.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.1MB 5.5MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn==0.19.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 5)) (0.19.1)\n",
      "Requirement already satisfied: six==1.11.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 6)) (1.11.0)\n",
      "Collecting zipline===1.2.0 (from -r requirements.txt (line 7))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d3/689f2a940478b82ac57c751a40460598221fd82b0449a7a8f7eef47a3bcc/zipline-1.2.0.tar.gz (659kB)\n",
      "\u001b[K    100% |████████████████████████████████| 665kB 6.4MB/s eta 0:00:01    72% |███████████████████████▍        | 481kB 10.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2 in /opt/conda/lib/python3.6/site-packages (from pandas==0.18.1->-r requirements.txt (line 3)) (2.6.1)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.6/site-packages (from pandas==0.18.1->-r requirements.txt (line 3)) (2017.3)\n",
      "Requirement already satisfied: decorator>=4.0.6 in /opt/conda/lib/python3.6/site-packages (from plotly==2.2.3->-r requirements.txt (line 4)) (4.0.11)\n",
      "Requirement already satisfied: nbformat>=4.2 in /opt/conda/lib/python3.6/site-packages (from plotly==2.2.3->-r requirements.txt (line 4)) (4.4.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from plotly==2.2.3->-r requirements.txt (line 4)) (2.18.4)\n",
      "Requirement already satisfied: pip>=7.1.0 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 7)) (18.1)\n",
      "Requirement already satisfied: setuptools>18.0 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 7)) (38.4.0)\n",
      "Collecting Logbook>=0.12.5 (from zipline===1.2.0->-r requirements.txt (line 7))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2f/d9/16ac346f7c0102835814cc9e5b684aaadea101560bb932a2403bd26b2320/Logbook-1.5.3.tar.gz (85kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 9.2MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting requests-file>=1.4.1 (from zipline===1.2.0->-r requirements.txt (line 7))\n",
      "  Downloading https://files.pythonhosted.org/packages/77/86/cdb5e8eaed90796aa83a6d9f75cfbd37af553c47a291cd47bc410ef9bdb2/requests_file-1.5.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: scipy>=0.17.1 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 7)) (1.2.1)\n",
      "Collecting pandas-datareader<0.6,>=0.2.1 (from zipline===1.2.0->-r requirements.txt (line 7))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/c5/cc720f531bbde0efeab940de400d0fcc95e87770a3abcd7f90d6d52a3302/pandas_datareader-0.5.0-py2.py3-none-any.whl (74kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 9.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: patsy>=0.4.0 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 7)) (0.4.1)\n",
      "Requirement already satisfied: statsmodels>=0.6.1 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 7)) (0.8.0)\n",
      "Requirement already satisfied: Cython>=0.25.2 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 7)) (0.29.7)\n",
      "Collecting cyordereddict>=0.2.2 (from zipline===1.2.0->-r requirements.txt (line 7))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/1a/364cbfd927be1b743c7f0a985a7f1f7e8a51469619f9fefe4ee9240ba210/cyordereddict-1.0.0.tar.gz (138kB)\n",
      "\u001b[K    100% |████████████████████████████████| 143kB 5.6MB/s ta 0:00:01    51% |████████████████▋               | 71kB 12.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting bottleneck>=1.0.0 (from zipline===1.2.0->-r requirements.txt (line 7))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/08/278c6ee569458e168096f6b51019cc1c81c288da3d1026a22ee2ccead102/Bottleneck-1.3.2.tar.gz (88kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 9.1MB/s ta 0:00:011\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting contextlib2>=0.4.0 (from zipline===1.2.0->-r requirements.txt (line 7))\n",
      "  Downloading https://files.pythonhosted.org/packages/85/60/370352f7ef6aa96c52fb001831622f50f923c1d575427d021b8ab3311236/contextlib2-0.6.0.post1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: networkx<2.0,>=1.9.1 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 7)) (1.11)\n",
      "Requirement already satisfied: numexpr>=2.6.1 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 7)) (2.6.4)\n",
      "Collecting bcolz<1,>=0.12.1 (from zipline===1.2.0->-r requirements.txt (line 7))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/8b/1ffa01f872cac36173c5eb95b58c01040d8d25f1b242c48577f4104cd3ab/bcolz-0.12.1.tar.gz (622kB)\n",
      "\u001b[K    100% |████████████████████████████████| 624kB 9.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: click>=4.0.0 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 7)) (6.7)\n",
      "Requirement already satisfied: toolz>=0.8.2 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 7)) (0.8.2)\n",
      "Collecting multipledispatch>=0.4.8 (from zipline===1.2.0->-r requirements.txt (line 7))\n",
      "  Downloading https://files.pythonhosted.org/packages/89/79/429ecef45fd5e4504f7474d4c3c3c4668c267be3370e4c2fd33e61506833/multipledispatch-0.6.0-py3-none-any.whl\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 7)) (1.0)\n",
      "Requirement already satisfied: Mako>=1.0.1 in /opt/conda/lib/python3.6/site-packages/Mako-1.0.7-py3.6.egg (from zipline===1.2.0->-r requirements.txt (line 7)) (1.0.7)\n",
      "Collecting alembic>=0.7.7 (from zipline===1.2.0->-r requirements.txt (line 7))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/42/f73279458f33ccd1ece2285c577f6882e2c7ba80054a7518854576c452cd/alembic-1.5.6-py2.py3-none-any.whl (159kB)\n",
      "\u001b[K    100% |████████████████████████████████| 163kB 7.0MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting sortedcontainers>=1.4.4 (from zipline===1.2.0->-r requirements.txt (line 7))\n",
      "  Downloading https://files.pythonhosted.org/packages/20/4d/a7046ae1a1a4cc4e9bbed194c387086f06b25038be596543d026946330c9/sortedcontainers-2.3.0-py2.py3-none-any.whl\n",
      "Collecting intervaltree>=2.1.0 (from zipline===1.2.0->-r requirements.txt (line 7))\n",
      "  Downloading https://files.pythonhosted.org/packages/50/fb/396d568039d21344639db96d940d40eb62befe704ef849b27949ded5c3bb/intervaltree-3.1.0.tar.gz\n",
      "Collecting lru-dict>=1.1.4 (from zipline===1.2.0->-r requirements.txt (line 7))\n",
      "  Downloading https://files.pythonhosted.org/packages/68/ea/997af58d4e6da019ad825a412f93081d9df67e9dda11cfb026a3d7cd0b6c/lru-dict-1.1.7.tar.gz\n",
      "Collecting empyrical>=0.4.2 (from zipline===1.2.0->-r requirements.txt (line 7))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/43/1b997c21411c6ab7c96dc034e160198272c7a785aeea7654c9bcf98bec83/empyrical-0.5.5.tar.gz (52kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 8.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tables>=3.3.0 (from zipline===1.2.0->-r requirements.txt (line 7))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/c3/8fd9e3bb21872f9d69eb93b3014c86479864cca94e625fd03713ccacec80/tables-3.6.1-cp36-cp36m-manylinux1_x86_64.whl (4.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 4.3MB 1.7MB/s ta 0:00:011    35% |███████████▏                    | 1.5MB 11.4MB/s eta 0:00:01    47% |███████████████                 | 2.0MB 10.5MB/s eta 0:00:01    58% |██████████████████▉             | 2.5MB 11.1MB/s eta 0:00:01    92% |█████████████████████████████▊  | 4.0MB 9.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2->plotly==2.2.3->-r requirements.txt (line 4)) (2.6.0)\n",
      "Requirement already satisfied: traitlets>=4.1 in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2->plotly==2.2.3->-r requirements.txt (line 4)) (4.3.2)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2->plotly==2.2.3->-r requirements.txt (line 4)) (0.2.0)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2->plotly==2.2.3->-r requirements.txt (line 4)) (4.4.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->plotly==2.2.3->-r requirements.txt (line 4)) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->plotly==2.2.3->-r requirements.txt (line 4)) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->plotly==2.2.3->-r requirements.txt (line 4)) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->plotly==2.2.3->-r requirements.txt (line 4)) (2019.11.28)\n",
      "Collecting requests-ftp (from pandas-datareader<0.6,>=0.2.1->zipline===1.2.0->-r requirements.txt (line 7))\n",
      "  Downloading https://files.pythonhosted.org/packages/3d/ca/14b2ad1e93b5195eeaf56b86b7ecfd5ea2d5754a68d17aeb1e5b9f95b3cf/requests-ftp-0.3.1.tar.gz\n",
      "Collecting python-editor>=0.3 (from alembic>=0.7.7->zipline===1.2.0->-r requirements.txt (line 7))\n",
      "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
      "Building wheels for collected packages: pandas, plotly, zipline, Logbook, cyordereddict, bottleneck, bcolz, intervaltree, lru-dict, empyrical, requests-ftp\n",
      "  Running setup.py bdist_wheel for pandas ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/a3/08/c3/8fdd52954d4b415624cff43c6dd32a22bac90306976a98f4af\n",
      "  Running setup.py bdist_wheel for plotly ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/98/54/81/dd92d5b0858fac680cd7bdb8800eb26c001dd9f5dc8b1bc0ba\n",
      "  Running setup.py bdist_wheel for zipline ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/5d/20/7d/b48368c8634b1cb6cc7232833b2780a265d4217c0ad2e3d24c\n",
      "  Running setup.py bdist_wheel for Logbook ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/d2/70/07/68b99a8e05dcd1ab194a8e0ccb9e4d0ac5dd6d8d139c7149b4\n",
      "  Running setup.py bdist_wheel for cyordereddict ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/0b/9d/8b/5bf3e22c1edd59b50f11bb19dec9dfcfe5a479fc7ace02b61f\n",
      "  Running setup.py bdist_wheel for bottleneck ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/97/a9/12/41b13e8b44889ab05ec4dcc91f27da21634bacf2a0e87473b8\n",
      "  Running setup.py bdist_wheel for bcolz ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/c5/cc/1b/2cf1f88959af5d7f4d449b7fc6c9452d0ecbd86fd61a9ee376\n",
      "  Running setup.py bdist_wheel for intervaltree ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/f3/f2/66/e9c30d3e9499e65ea2fa0d07c002e64de63bd0adaa49c445bf\n",
      "  Running setup.py bdist_wheel for lru-dict ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/ae/51/23/0a416781dead9225c7d66d25b9f223c7e32304e99a0b01d566\n",
      "  Running setup.py bdist_wheel for empyrical ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/ea/b2/c8/6769d8444d2f2e608fae2641833110668d0ffd1abeb2e9f3fc\n",
      "  Running setup.py bdist_wheel for requests-ftp ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/2a/98/32/37195e45a3392a73d9f65c488cbea30fe5bad76aaef4d6b020\n",
      "Successfully built pandas plotly zipline Logbook cyordereddict bottleneck bcolz intervaltree lru-dict empyrical requests-ftp\n",
      "\u001b[31mtensorflow 1.3.0 requires tensorflow-tensorboard<0.2.0,>=0.1.0, which is not installed.\u001b[0m\n",
      "Installing collected packages: SQLAlchemy, numpy, pandas, plotly, Logbook, requests-file, requests-ftp, pandas-datareader, cyordereddict, bottleneck, contextlib2, bcolz, multipledispatch, python-editor, alembic, sortedcontainers, intervaltree, lru-dict, empyrical, tables, zipline\n",
      "  Found existing installation: SQLAlchemy 1.1.13\n",
      "    Uninstalling SQLAlchemy-1.1.13:\n",
      "      Successfully uninstalled SQLAlchemy-1.1.13\n",
      "  Found existing installation: numpy 1.12.1\n",
      "    Uninstalling numpy-1.12.1:\n",
      "      Successfully uninstalled numpy-1.12.1\n",
      "  Found existing installation: pandas 0.23.3\n",
      "    Uninstalling pandas-0.23.3:\n",
      "      Successfully uninstalled pandas-0.23.3\n",
      "  Found existing installation: plotly 2.0.15\n",
      "    Uninstalling plotly-2.0.15:\n",
      "      Successfully uninstalled plotly-2.0.15\n",
      "Successfully installed Logbook-1.5.3 SQLAlchemy-1.3.22 alembic-1.5.6 bcolz-0.12.1 bottleneck-1.3.2 contextlib2-0.6.0.post1 cyordereddict-1.0.0 empyrical-0.5.5 intervaltree-3.1.0 lru-dict-1.1.7 multipledispatch-0.6.0 numpy-1.14.5 pandas-0.18.1 pandas-datareader-0.5.0 plotly-2.2.3 python-editor-1.0.4 requests-file-1.5.1 requests-ftp-0.3.1 sortedcontainers-2.3.0 tables-3.6.1 zipline-1.2.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import quiz_helper\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import quiz_helper\n",
    "from zipline.data import bundles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Registered\n"
     ]
    }
   ],
   "source": [
    "os.environ['ZIPLINE_ROOT'] = os.path.join(os.getcwd(), '..', '..','data','module_4_quizzes_eod')\n",
    "ingest_func = bundles.csvdir.csvdir_equities(['daily'], quiz_helper.EOD_BUNDLE_NAME)\n",
    "bundles.register(quiz_helper.EOD_BUNDLE_NAME, ingest_func)\n",
    "print('Data Registered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build pipeline engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipline.pipeline import Pipeline\n",
    "from zipline.pipeline.factors import AverageDollarVolume\n",
    "from zipline.utils.calendars import get_calendar\n",
    "\n",
    "universe = AverageDollarVolume(window_length=120).top(500) \n",
    "trading_calendar = get_calendar('NYSE') \n",
    "bundle_data = bundles.load(quiz_helper.EOD_BUNDLE_NAME)\n",
    "engine = quiz_helper.build_pipeline_engine(bundle_data, trading_calendar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data¶\n",
    "With the pipeline engine built, let's get the stocks at the end of the period in the universe we're using. We'll use these tickers to generate the returns data for the our risk model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Equity(0 [A]),\n",
       " Equity(1 [AAL]),\n",
       " Equity(2 [AAP]),\n",
       " Equity(3 [AAPL]),\n",
       " Equity(4 [ABBV])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "universe_end_date = pd.Timestamp('2016-01-05', tz='UTC')\n",
    "\n",
    "universe_tickers = engine\\\n",
    "    .run_pipeline(\n",
    "        Pipeline(screen=universe),\n",
    "        universe_end_date,\n",
    "        universe_end_date)\\\n",
    "    .index.get_level_values(1)\\\n",
    "    .values.tolist()\n",
    "    \n",
    "universe_tickers[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "490"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(universe_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipline.data.data_portal import DataPortal\n",
    "\n",
    "data_portal = DataPortal(\n",
    "    bundle_data.asset_finder,\n",
    "    trading_calendar=trading_calendar,\n",
    "    first_trading_day=bundle_data.equity_daily_bar_reader.first_trading_day,\n",
    "    equity_minute_reader=None,\n",
    "    equity_daily_reader=bundle_data.equity_daily_bar_reader,\n",
    "    adjustment_reader=bundle_data.adjustment_reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get pricing data helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quiz_helper import get_pricing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get pricing data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Equity(0 [A])</th>\n",
       "      <th>Equity(1 [AAL])</th>\n",
       "      <th>Equity(2 [AAP])</th>\n",
       "      <th>Equity(3 [AAPL])</th>\n",
       "      <th>Equity(4 [ABBV])</th>\n",
       "      <th>Equity(5 [ABC])</th>\n",
       "      <th>Equity(6 [ABT])</th>\n",
       "      <th>Equity(7 [ACN])</th>\n",
       "      <th>Equity(8 [ADBE])</th>\n",
       "      <th>Equity(9 [ADI])</th>\n",
       "      <th>...</th>\n",
       "      <th>Equity(481 [XL])</th>\n",
       "      <th>Equity(482 [XLNX])</th>\n",
       "      <th>Equity(483 [XOM])</th>\n",
       "      <th>Equity(484 [XRAY])</th>\n",
       "      <th>Equity(485 [XRX])</th>\n",
       "      <th>Equity(486 [XYL])</th>\n",
       "      <th>Equity(487 [YUM])</th>\n",
       "      <th>Equity(488 [ZBH])</th>\n",
       "      <th>Equity(489 [ZION])</th>\n",
       "      <th>Equity(490 [ZTS])</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-07 00:00:00+00:00</th>\n",
       "      <td>0.008437</td>\n",
       "      <td>0.014230</td>\n",
       "      <td>0.026702</td>\n",
       "      <td>0.007146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>0.004165</td>\n",
       "      <td>0.001648</td>\n",
       "      <td>-0.007127</td>\n",
       "      <td>-0.005818</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001838</td>\n",
       "      <td>-0.005619</td>\n",
       "      <td>0.005461</td>\n",
       "      <td>-0.004044</td>\n",
       "      <td>-0.013953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012457</td>\n",
       "      <td>-0.000181</td>\n",
       "      <td>-0.010458</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-10 00:00:00+00:00</th>\n",
       "      <td>-0.004174</td>\n",
       "      <td>0.006195</td>\n",
       "      <td>0.007435</td>\n",
       "      <td>0.018852</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.005714</td>\n",
       "      <td>-0.008896</td>\n",
       "      <td>-0.008854</td>\n",
       "      <td>0.028714</td>\n",
       "      <td>0.002926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.007814</td>\n",
       "      <td>-0.006081</td>\n",
       "      <td>0.010466</td>\n",
       "      <td>0.009733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.007784</td>\n",
       "      <td>-0.017945</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-11 00:00:00+00:00</th>\n",
       "      <td>-0.001886</td>\n",
       "      <td>-0.043644</td>\n",
       "      <td>-0.005927</td>\n",
       "      <td>-0.002367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009783</td>\n",
       "      <td>-0.002067</td>\n",
       "      <td>0.013717</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>0.008753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.010179</td>\n",
       "      <td>0.007442</td>\n",
       "      <td>0.007351</td>\n",
       "      <td>0.006116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.006470</td>\n",
       "      <td>0.035676</td>\n",
       "      <td>0.007467</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-12 00:00:00+00:00</th>\n",
       "      <td>0.017254</td>\n",
       "      <td>-0.008237</td>\n",
       "      <td>0.013387</td>\n",
       "      <td>0.008133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.005979</td>\n",
       "      <td>-0.001011</td>\n",
       "      <td>0.022969</td>\n",
       "      <td>0.017950</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004986</td>\n",
       "      <td>0.015666</td>\n",
       "      <td>0.011763</td>\n",
       "      <td>0.027182</td>\n",
       "      <td>0.004386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.014741</td>\n",
       "      <td>-0.011903</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-13 00:00:00+00:00</th>\n",
       "      <td>-0.004559</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>0.003031</td>\n",
       "      <td>0.003657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>-0.004451</td>\n",
       "      <td>-0.000400</td>\n",
       "      <td>-0.005719</td>\n",
       "      <td>-0.005012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030499</td>\n",
       "      <td>-0.003217</td>\n",
       "      <td>0.001694</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>-0.018235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.005084</td>\n",
       "      <td>-0.004665</td>\n",
       "      <td>-0.009178</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 490 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Equity(0 [A])  Equity(1 [AAL])  Equity(2 [AAP])  \\\n",
       "2011-01-07 00:00:00+00:00       0.008437         0.014230         0.026702   \n",
       "2011-01-10 00:00:00+00:00      -0.004174         0.006195         0.007435   \n",
       "2011-01-11 00:00:00+00:00      -0.001886        -0.043644        -0.005927   \n",
       "2011-01-12 00:00:00+00:00       0.017254        -0.008237         0.013387   \n",
       "2011-01-13 00:00:00+00:00      -0.004559         0.000955         0.003031   \n",
       "\n",
       "                           Equity(3 [AAPL])  Equity(4 [ABBV])  \\\n",
       "2011-01-07 00:00:00+00:00          0.007146               0.0   \n",
       "2011-01-10 00:00:00+00:00          0.018852               0.0   \n",
       "2011-01-11 00:00:00+00:00         -0.002367               0.0   \n",
       "2011-01-12 00:00:00+00:00          0.008133               0.0   \n",
       "2011-01-13 00:00:00+00:00          0.003657               0.0   \n",
       "\n",
       "                           Equity(5 [ABC])  Equity(6 [ABT])  Equity(7 [ACN])  \\\n",
       "2011-01-07 00:00:00+00:00         0.001994         0.004165         0.001648   \n",
       "2011-01-10 00:00:00+00:00        -0.005714        -0.008896        -0.008854   \n",
       "2011-01-11 00:00:00+00:00         0.009783        -0.002067         0.013717   \n",
       "2011-01-12 00:00:00+00:00        -0.005979        -0.001011         0.022969   \n",
       "2011-01-13 00:00:00+00:00         0.014925        -0.004451        -0.000400   \n",
       "\n",
       "                           Equity(8 [ADBE])  Equity(9 [ADI])  \\\n",
       "2011-01-07 00:00:00+00:00         -0.007127        -0.005818   \n",
       "2011-01-10 00:00:00+00:00          0.028714         0.002926   \n",
       "2011-01-11 00:00:00+00:00          0.000607         0.008753   \n",
       "2011-01-12 00:00:00+00:00          0.017950         0.000257   \n",
       "2011-01-13 00:00:00+00:00         -0.005719        -0.005012   \n",
       "\n",
       "                                 ...          Equity(481 [XL])  \\\n",
       "2011-01-07 00:00:00+00:00        ...                 -0.001838   \n",
       "2011-01-10 00:00:00+00:00        ...                  0.000947   \n",
       "2011-01-11 00:00:00+00:00        ...                  0.001314   \n",
       "2011-01-12 00:00:00+00:00        ...                  0.004986   \n",
       "2011-01-13 00:00:00+00:00        ...                  0.030499   \n",
       "\n",
       "                           Equity(482 [XLNX])  Equity(483 [XOM])  \\\n",
       "2011-01-07 00:00:00+00:00           -0.005619           0.005461   \n",
       "2011-01-10 00:00:00+00:00            0.007814          -0.006081   \n",
       "2011-01-11 00:00:00+00:00            0.010179           0.007442   \n",
       "2011-01-12 00:00:00+00:00            0.015666           0.011763   \n",
       "2011-01-13 00:00:00+00:00           -0.003217           0.001694   \n",
       "\n",
       "                           Equity(484 [XRAY])  Equity(485 [XRX])  \\\n",
       "2011-01-07 00:00:00+00:00           -0.004044          -0.013953   \n",
       "2011-01-10 00:00:00+00:00            0.010466           0.009733   \n",
       "2011-01-11 00:00:00+00:00            0.007351           0.006116   \n",
       "2011-01-12 00:00:00+00:00            0.027182           0.004386   \n",
       "2011-01-13 00:00:00+00:00            0.000547          -0.018235   \n",
       "\n",
       "                           Equity(486 [XYL])  Equity(487 [YUM])  \\\n",
       "2011-01-07 00:00:00+00:00                0.0           0.012457   \n",
       "2011-01-10 00:00:00+00:00                0.0           0.001440   \n",
       "2011-01-11 00:00:00+00:00                0.0          -0.006470   \n",
       "2011-01-12 00:00:00+00:00                0.0           0.002631   \n",
       "2011-01-13 00:00:00+00:00                0.0          -0.005084   \n",
       "\n",
       "                           Equity(488 [ZBH])  Equity(489 [ZION])  \\\n",
       "2011-01-07 00:00:00+00:00          -0.000181           -0.010458   \n",
       "2011-01-10 00:00:00+00:00           0.007784           -0.017945   \n",
       "2011-01-11 00:00:00+00:00           0.035676            0.007467   \n",
       "2011-01-12 00:00:00+00:00           0.014741           -0.011903   \n",
       "2011-01-13 00:00:00+00:00          -0.004665           -0.009178   \n",
       "\n",
       "                           Equity(490 [ZTS])  \n",
       "2011-01-07 00:00:00+00:00                0.0  \n",
       "2011-01-10 00:00:00+00:00                0.0  \n",
       "2011-01-11 00:00:00+00:00                0.0  \n",
       "2011-01-12 00:00:00+00:00                0.0  \n",
       "2011-01-13 00:00:00+00:00                0.0  \n",
       "\n",
       "[5 rows x 490 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns_df = \\\n",
    "    get_pricing(\n",
    "        data_portal,\n",
    "        trading_calendar,\n",
    "        universe_tickers,\n",
    "        universe_end_date - pd.DateOffset(years=5),\n",
    "        universe_end_date)\\\n",
    "    .pct_change()[1:].fillna(0) #convert prices into returns\n",
    "\n",
    "returns_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's look at a two stock portfolio\n",
    "\n",
    "Let's pretend we have a portfolio of two stocks.  We'll pick Apple and Microsoft in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset_return_aapl</th>\n",
       "      <th>asset_return_msft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-07 00:00:00+00:00</th>\n",
       "      <td>0.007146</td>\n",
       "      <td>-0.007597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-10 00:00:00+00:00</th>\n",
       "      <td>0.018852</td>\n",
       "      <td>-0.013311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           asset_return_aapl  asset_return_msft\n",
       "2011-01-07 00:00:00+00:00           0.007146          -0.007597\n",
       "2011-01-10 00:00:00+00:00           0.018852          -0.013311"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_col = returns_df.columns[3]\n",
    "msft_col = returns_df.columns[312]\n",
    "asset_return_1 = returns_df[aapl_col].rename('asset_return_aapl')\n",
    "asset_return_2 = returns_df[msft_col].rename('asset_return_msft')\n",
    "asset_return_df = pd.concat([asset_return_1,asset_return_2],axis=1)\n",
    "asset_return_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factor returns\n",
    "Let's make up a \"factor\" by taking an average of all stocks in our list.  You can think of this as an equal weighted index of the 490 stocks, kind of like a measure of the \"market\".  We'll also make another factor by calculating the median of all the stocks.  These are mainly intended to help us generate some data to work with.  We'll go into how some common risk factors are generated later in the lessons.\n",
    "\n",
    "Also note that we're setting axis=1 so that we calculate a value for each time period (row) instead of one value for each column (assets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_return_1 = returns_df.mean(axis=1)\n",
    "factor_return_2 = returns_df.median(axis=1)\n",
    "factor_return_l = [factor_return_1, factor_return_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factor exposures\n",
    "\n",
    "Factor exposures refer to how \"exposed\" a stock is to each factor.  We'll get into this more later.  For now, just think of this as one number for each stock, for each of the factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For now, just assume that we're calculating a number for each \n",
    "stock, for each factor, which represents how \"exposed\" each stock is\n",
    "to each factor. \n",
    "We'll discuss how factor exposure is calculated later in the lessons.\n",
    "\"\"\"\n",
    "def get_factor_exposures(factor_return_l, asset_return):\n",
    "    lr = LinearRegression()\n",
    "    X = np.array(factor_return_l).T\n",
    "    y = np.array(asset_return.values)\n",
    "    lr.fit(X,y)\n",
    "    return lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_exposure_l = []\n",
    "for i in range(len(asset_return_df.columns)):\n",
    "    factor_exposure_l.append(\n",
    "        get_factor_exposures(factor_return_l,\n",
    "                             asset_return_df[asset_return_df.columns[i]]\n",
    "                            ))\n",
    "    \n",
    "factor_exposure_a = np.array(factor_exposure_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "factor_exposures for asset 1 [ 1.35101534 -0.58353198]\n",
      "factor_exposures for asset 2 [-0.2283345   1.16364007]\n"
     ]
    }
   ],
   "source": [
    "print(f\"factor_exposures for asset 1 {factor_exposure_a[0]}\")\n",
    "print(f\"factor_exposures for asset 2 {factor_exposure_a[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz: Variance of stock 1\n",
    "\n",
    "Calculate the variance of stock 1.  \n",
    "$\\textrm{Var}(r_{1}) = \\beta_{1,1}^2 \\textrm{Var}(f_{1}) + \\beta_{1,2}^2 \\textrm{Var}(f_{2}) + 2\\beta_{1,1}\\beta_{1,2}\\textrm{Cov}(f_{1},f_{2}) + \\textrm{Var}(s_{1})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_exposure_1_1 = factor_exposure_a[0][0]\n",
    "factor_exposure_1_2 = factor_exposure_a[0][1]\n",
    "common_return_1 = factor_exposure_1_1 * factor_return_1 + factor_exposure_1_2 * factor_return_2\n",
    "specific_return_1 = asset_return_1 - common_return_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.02562520e-04, 9.79887017e-05],\n",
       "       [9.79887017e-05, 9.44523986e-05]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covm_f1_f2 = np.cov(factor_return_1, factor_return_2,ddof=1) #this calculates a covariance matrix\n",
    "covm_f1_f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance of asset 1: 0.00028209\n"
     ]
    }
   ],
   "source": [
    "# TODO: get the variance of each factor, and covariances from the covariance matrix covm_f1_f2\n",
    "var_f1 = covm_f1_f2[0,0]\n",
    "var_f2 = covm_f1_f2[1,1]\n",
    "cov_f1_f2 = covm_f1_f2[1,0]\n",
    "\n",
    "# TODO: calculate the specific variance.  \n",
    "var_s_1 = np.var(specific_return_1, ddof=1)\n",
    "\n",
    "# TODO: calculate the variance of asset 1 in terms of the factors and specific variance\n",
    "var_asset_1 = (factor_exposure_1_1**2 * var_f1) + \\\n",
    "                (factor_exposure_1_2**2 * var_f2) + \\\n",
    "                2 * factor_exposure_1_1 * factor_exposure_1_2 * cov_f1_f2 + \\\n",
    "                var_s_1\n",
    "print(f\"variance of asset 1: {var_asset_1:.8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz 2: Variance of stock 2\n",
    "Calculate the variance of stock 2.  \n",
    "$\\textrm{Var}(r_{2}) = \\beta_{2,1}^2 \\textrm{Var}(f_{1}) + \\beta_{2,2}^2 \\textrm{Var}(f_{2}) + 2\\beta_{2,1}\\beta_{2,2}\\textrm{Cov}(f_{1},f_{2}) + \\textrm{Var}(s_{2})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_exposure_2_1 = factor_exposure_a[1][0]\n",
    "factor_exposure_2_2 = factor_exposure_a[1][1]\n",
    "common_return_2 = factor_exposure_2_1 * factor_return_1 + factor_exposure_2_2 * factor_return_2\n",
    "specific_return_2 = asset_return_2 - common_return_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance of asset 2: 0.00021856\n"
     ]
    }
   ],
   "source": [
    "# Notice we already calculated the variance and covariances of the factors\n",
    "\n",
    "# TODO: calculate the specific variance of asset 2\n",
    "var_s_2 = np.var(specific_return_2, ddof=1)\n",
    "\n",
    "# TODO: calcualte the variance of asset 2 in terms of the factors and specific variance\n",
    "var_asset_2 = (factor_exposure_2_1**2 * var_f1) + \\\n",
    "                (factor_exposure_2_2**2 * var_f2) + \\\n",
    "                2 * factor_exposure_2_1 * factor_exposure_2_2 * cov_f1_f2 + \\\n",
    "                var_s_2\n",
    "            \n",
    "print(f\"variance of asset 2: {var_asset_2:.8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz 3: Covariance of stocks 1 and 2\n",
    "Calculate the covariance of stock 1 and 2.  \n",
    "$\\textrm{Cov}(r_{1},r_{2}) = \\beta_{1,1}\\beta_{2,1}\\textrm{Var}(f_{1}) + \\beta_{1,1}\\beta_{2,2}\\textrm{Cov}(f_{1},f_{2}) + \\beta_{1,2}\\beta_{2,1}\\textrm{Cov}(f_{1},f_{2}) + \\beta_{1,2}\\beta_{2,2}\\textrm{Var}(f_{2})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covariance of assets 1 and 2: 0.00007133\n"
     ]
    }
   ],
   "source": [
    "# TODO: calculate the covariance of assets 1 and 2 in terms of the factors\n",
    "cov_asset_1_2 = (factor_exposure_1_1 * factor_exposure_2_1 * var_f1) + \\\n",
    "            (factor_exposure_1_1 * factor_exposure_2_2 * cov_f1_f2) + \\\n",
    "            (factor_exposure_1_2 * factor_exposure_2_1 * cov_f1_f2) + \\\n",
    "            (factor_exposure_1_2 * factor_exposure_2_2 * var_f2)\n",
    "print(f\"covariance of assets 1 and 2: {cov_asset_1_2:.8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz 4: Do it with Matrices!\n",
    "\n",
    "Create matrices $\\mathbf{F}$, $\\mathbf{B}$ and $\\mathbf{S}$, where  \n",
    "$\\mathbf{F}= \\begin{pmatrix}\n",
    "\\textrm{Var}(f_1) & \\textrm{Cov}(f_1,f_2) \\\\ \n",
    "\\textrm{Cov}(f_2,f_1) & \\textrm{Var}(f_2) \n",
    "\\end{pmatrix}$\n",
    "is the covariance matrix of factors,  \n",
    "\n",
    "$\\mathbf{B} = \\begin{pmatrix}\n",
    "\\beta_{1,1}, \\beta_{1,2}\\\\ \n",
    "\\beta_{2,1}, \\beta_{2,2}\n",
    "\\end{pmatrix}$ \n",
    "is the matrix of factor exposures, and  \n",
    "\n",
    "$\\mathbf{S} = \\begin{pmatrix}\n",
    "\\textrm{Var}(s_i) & 0\\\\ \n",
    "0 & \\textrm{Var}(s_j)\n",
    "\\end{pmatrix}$\n",
    "is the matrix of specific variances.  \n",
    "\n",
    "Then calculate $\\mathbf{BFB}^T$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.02562520e-04, 9.79887017e-05],\n",
       "       [9.79887017e-05, 9.44523986e-05]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: covariance matrix of factors\n",
    "F = covm_f1_f2\n",
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.35101534, -0.58353198],\n",
       "       [-0.2283345 ,  1.16364007]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: matrix of factor exposures\n",
    "B = factor_exposure_a\n",
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hint: for diagonal matrices\n",
    "You can try using [numpy.diag](https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.diag.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00021723, 0.        ],\n",
       "       [0.        , 0.00013739]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: matrix of specific variances\n",
    "S = np.diag([var_s_1, var_s_2])\n",
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.38563538e-04, -5.71795414e-05],\n",
       "        [-2.23742008e-05,  1.09908596e-04]]),\n",
       " array([[8.13839965e-05, 7.72682440e-05],\n",
       "        [9.06050184e-05, 8.75343948e-05]]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B * F, B.dot(F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget that B * F is not the same as B.dot(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covariance matrix of assets 1 and 2 \n",
      "[[2.82089786e-04 7.13296510e-05]\n",
      " [7.13296510e-05 2.18561378e-04]]\n"
     ]
    }
   ],
   "source": [
    "# TODO: covariance matrix of assets\n",
    "covm_assets = B.dot(F).dot(B.T) + S\n",
    "print(f\"covariance matrix of assets 1 and 2 \\n{covm_assets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "[Solution notebook](covariance_matrix_assets_solution.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
